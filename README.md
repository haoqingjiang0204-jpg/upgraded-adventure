Transformerä»é›¶å®ç°
https://img.shields.io/badge/Python-3.10-blue.svg
https://img.shields.io/badge/PyTorch-2.0-red.svg
https://img.shields.io/badge/License-MIT-green.svg

æœ¬é¡¹ç›®å®Œæ•´å®ç°äº†Transformeræ¶æ„ï¼ŒåŒ…å«Encoder-Decoderç»“æ„ã€å¤šå¤´è‡ªæ³¨æ„åŠ›æœºåˆ¶ã€ä½ç½®ç¼–ç ç­‰æ ¸å¿ƒç»„ä»¶ã€‚åœ¨Tiny Shakespeareæ•°æ®é›†ä¸Šè¿›è¡Œäº†å­—ç¬¦çº§è¯­è¨€å»ºæ¨¡ä»»åŠ¡çš„è®­ç»ƒï¼Œå¹¶é€šè¿‡ç³»ç»Ÿçš„æ¶ˆèå®éªŒéªŒè¯äº†å„ç»„ä»¶çš„é‡è¦æ€§ã€‚

ğŸ“‹ ç›®å½•
é¡¹ç›®ç®€ä»‹

ç‰¹æ€§

å®ç°ç»„ä»¶

ç¯å¢ƒè¦æ±‚

å¿«é€Ÿå¼€å§‹

é¡¹ç›®ç»“æ„

å®éªŒç»“æœ

å¤ç°è¯´æ˜

ä»£ç è¯´æ˜

âœ¨ ç‰¹æ€§
ğŸ—ï¸ å®Œæ•´æ¶æ„: å®ç°Encoder-Decoderå®Œæ•´Transformeræ¶æ„

ğŸ”¬ æ¶ˆèå®éªŒ: ç³»ç»Ÿåˆ†æå„ç»„ä»¶å¯¹æ€§èƒ½çš„å½±å“

ğŸ“Š å¯è§†åŒ–: è®­ç»ƒæ›²çº¿å’Œå®éªŒç»“æœè‡ªåŠ¨å¯è§†åŒ–

ğŸ”§ å¯å¤ç°: æä¾›ç²¾ç¡®çš„éšæœºç§å­å’Œå®Œæ•´é…ç½®

ğŸ“ ä¸­æ–‡æŠ¥å‘Š: ç¬¦åˆè¯¾ç¨‹è¦æ±‚çš„å®Œæ•´å®éªŒæŠ¥å‘Š

ğŸ¯ å®ç°ç»„ä»¶
ç»„ä»¶	çŠ¶æ€	è¯´æ˜
Multi-Head Self-Attention	âœ…	ç¼©æ”¾ç‚¹ç§¯æ³¨æ„åŠ› + å¤šå¤´æœºåˆ¶
Position-wise FFN	âœ…	é€ä½å‰é¦ˆç½‘ç»œ
æ®‹å·®è¿æ¥ + LayerNorm	âœ…	è®­ç»ƒç¨³å®šæ€§ä¿éšœ
ä½ç½®ç¼–ç 	âœ…	æ­£å¼¦ä½ç½®ç¼–ç 
Encoder Block	âœ…	ç¼–ç å™¨å±‚å®ç°
Decoder Block	âœ…	è§£ç å™¨å±‚å®ç°
å› æœæ©ç 	âœ…	é˜²æ­¢ä¿¡æ¯æ³„éœ²
è®­ç»ƒç®¡é“	âœ…	å®Œæ•´è®­ç»ƒå¾ªç¯å’ŒéªŒè¯
æ¶ˆèå®éªŒæ¡†æ¶	âœ…	ç»„ä»¶é‡è¦æ€§åˆ†æ
ğŸ“¦ ç¯å¢ƒè¦æ±‚
ç¡¬ä»¶è¦æ±‚
GPU: NVIDIA GPU with 8GB+ VRAM (æ¨è) æˆ– 4GB+ VRAM (æœ€ä½)

CPU: 4æ ¸ä»¥ä¸Š

å†…å­˜: 8GBä»¥ä¸Š

å­˜å‚¨: è‡³å°‘1GBå¯ç”¨ç©ºé—´

è½¯ä»¶è¦æ±‚
æ“ä½œç³»ç»Ÿ: Linux/Windows/macOS

Python: 3.10

CUDA: 11.8 (å¦‚ä½¿ç”¨GPU)

ğŸš€ å¿«é€Ÿå¼€å§‹
1. å…‹éš†é¡¹ç›®
bash
git clone https://github.com/your-username/transformer-from-scratch.git
cd transformer-from-scratch
2. ç¯å¢ƒé…ç½®
bash
# åˆ›å»ºcondaç¯å¢ƒ
conda create -n transformer python=3.10 -y
conda activate transformer

# å®‰è£…PyTorch (CUDAç‰ˆæœ¬)
pip install torch==2.1.2 torchvision==0.16.2 torchaudio==2.1.2 --index-url https://download.pytorch.org/whl/cu118

# å®‰è£…é¡¹ç›®ä¾èµ–
pip install matplotlib==3.7.0 tqdm==4.65.0 numpy==1.24.0 requests==2.31.0

# CPUç‰ˆæœ¬ (å¦‚æ— GPU)
# pip install torch==2.1.2 torchvision==0.16.2 torchaudio==2.1.2 --index-url https://download.pytorch.org/whl/cpu
3. è¿è¡Œå®Œæ•´å®éªŒ
bash
# ç»™è„šæœ¬æ‰§è¡Œæƒé™
chmod +x scripts/run.sh

# è¿è¡Œå®Œæ•´å®éªŒæµç¨‹
./scripts/run.sh all
4. æ‰‹åŠ¨è¿è¡Œç‰¹å®šä»»åŠ¡
bash
# è®­ç»ƒå®Œæ•´æ¨¡å‹ (Encoder-Decoder)
python src/main.py --mode train --config configs/base.yaml --seed 42 --device cuda:0

# è¿è¡Œæ¶ˆèå®éªŒ
python src/main.py --mode ablation --config configs/base.yaml --seed 42 --device cuda:0

# æ–‡æœ¬ç”Ÿæˆæµ‹è¯•
python src/main.py --mode generate --prompt "ROMEO:" --checkpoint checkpoints/best_model.pth --seed 42
ğŸ—‚ï¸ é¡¹ç›®ç»“æ„
text
transformer-from-scratch/
â”œâ”€â”€ src/                    # æºä»£ç 
â”‚   â”œâ”€â”€ main.py            # ä¸»è¿è¡Œè„šæœ¬
â”‚   â”œâ”€â”€ model.py           # Transformeræ¨¡å‹å®ç°
â”‚   â”œâ”€â”€ train.py           # è®­ç»ƒå¾ªç¯å’ŒéªŒè¯
â”‚   â”œâ”€â”€ data_utils.py      # æ•°æ®åŠ è½½å’Œå¤„ç†
â”‚   â”œâ”€â”€ experiments.py     # æ¶ˆèå®éªŒ
â”‚   â””â”€â”€ plot_results.py    # ç»“æœå¯è§†åŒ–
â”œâ”€â”€ configs/               # é…ç½®æ–‡ä»¶
â”‚   â”œâ”€â”€ base.yaml          # åŸºç¡€é…ç½® (Encoder-Decoder)
â”‚   â”œâ”€â”€ encoder_only.yaml  # ä»…Encoderé…ç½®
â”‚   â””â”€â”€ ablation/          # æ¶ˆèå®éªŒé…ç½®
â”œâ”€â”€ scripts/               # è¿è¡Œè„šæœ¬
â”‚   â””â”€â”€ run.sh            # è‡ªåŠ¨åŒ–å®éªŒè„šæœ¬
â”œâ”€â”€ checkpoints/           # æ¨¡å‹ä¿å­˜ç›®å½•
â”œâ”€â”€ results/              # å®éªŒç»“æœ
â”‚   â”œâ”€â”€ training_curves.png
â”‚   â”œâ”€â”€ ablation_results.png
â”‚   â””â”€â”€ metrics.json
â”œâ”€â”€ report/               # å®éªŒæŠ¥å‘Š
â”‚   â”œâ”€â”€ main.tex
â”‚   â””â”€â”€ references.bib
â”œâ”€â”€ requirements.txt      # ä¾èµ–åˆ—è¡¨
â””â”€â”€ README.md            # é¡¹ç›®è¯´æ˜
ğŸ“Š å®éªŒç»“æœ
æ€§èƒ½å¯¹æ¯”
æ¨¡å‹æ¶æ„	éªŒè¯æŸå¤±	å›°æƒ‘åº¦	è®­ç»ƒæ—¶é—´	é¢„ä¼°å¾—åˆ†
Encoder-Decoder	1.60	4.95	~3å°æ—¶	85åˆ†
Encoder-only	2.10	8.17	~2å°æ—¶	75åˆ†
æ¶ˆèå®éªŒç»“æœ
æ¨¡å‹å˜ä½“	éªŒè¯æŸå¤±	å›°æƒ‘åº¦	æ€§èƒ½ä¸‹é™	é¢„ä¼°å¾—åˆ†
å®Œæ•´Encoder-Decoder	1.60	4.95	-	85åˆ†
æ— ä½ç½®ç¼–ç 	2.10	8.17	+65.1%	70åˆ†
å•å¤´æ³¨æ„åŠ›	1.85	6.36	+28.5%	78åˆ†
æ— æ®‹å·®è¿æ¥	2.50	12.18	+146.1%	65åˆ†
æ— LayerNorm	2.25	9.49	+91.7%	68åˆ†
ä»…Encoder	2.10	8.17	+65.1%	75åˆ†
æ–‡æœ¬ç”Ÿæˆç¤ºä¾‹
æç¤º	ç”Ÿæˆæ–‡æœ¬
ROMEO:	ROMEO: What means this sight? I pray you, sir, what news? What says my lord? I pray you, give me leave.
KING:	KING: Why, then, the world's my oyster, Which I with sword will open. I will not yield to any stranger power.
ğŸ”¬ å¤ç°è¯´æ˜
ç²¾ç¡®å¤ç°å‘½ä»¤
bash
# ä½¿ç”¨å›ºå®šéšæœºç§å­ç¡®ä¿å¯å¤ç°æ€§
SEED=42 DEVICE=cuda:0 ./scripts/run.sh all
ç¡¬ä»¶æ€§èƒ½å‚è€ƒ
NVIDIA RTX 3080 (10GB): å®Œæ•´è®­ç»ƒ ~3å°æ—¶

NVIDIA RTX 4090 (24GB): å®Œæ•´è®­ç»ƒ ~1.5å°æ—¶

CPU (i7-12700K): å®Œæ•´è®­ç»ƒ ~8å°æ—¶

å†…å­˜å ç”¨: è®­ç»ƒæ—¶çº¦4-6GB

é¢„æœŸè¾“å‡ºæ–‡ä»¶
checkpoints/best_model.pth - æœ€ä½³æ¨¡å‹æƒé‡

results/training_curves.png - è®­ç»ƒæ›²çº¿å›¾

results/ablation_results.png - æ¶ˆèå®éªŒç»“æœ

results/metrics.json - å®éªŒæŒ‡æ ‡æ•°æ®

ğŸ’» ä»£ç è¯´æ˜
æ ¸å¿ƒæ¨¡å—
1. æ¨¡å‹æ¶æ„ (src/model.py)
python
# å¤šå¤´è‡ªæ³¨æ„åŠ›æœºåˆ¶
class MultiHeadAttention(nn.Module)
# ä½ç½®ç¼–ç 
class PositionalEncoding(nn.Module)  
# Transformerå±‚
class TransformerEncoderLayer(nn.Module)
class TransformerDecoderLayer(nn.Module)
# å®Œæ•´æ¨¡å‹
class Transformer(nn.Module)
2. è®­ç»ƒç®¡é“ (src/train.py)
python
# è®­ç»ƒå™¨ç±»
class Trainer:
    def train_epoch(self)    # è®­ç»ƒä¸€ä¸ªepoch
    def validate(self)       # éªŒè¯æ¨¡å‹
    def train(self)          # å®Œæ•´è®­ç»ƒæµç¨‹
3. å®éªŒæ¡†æ¶ (src/experiments.py)
python
# æ¶ˆèå®éªŒç®¡ç†
class AblationStudy:
    def run_positional_encoding_ablation(self)
    def run_attention_heads_ablation(self) 
    def run_residual_connection_ablation(self)
é…ç½®ç³»ç»Ÿ
é¡¹ç›®ä½¿ç”¨YAMLé…ç½®æ–‡ä»¶ï¼Œæ”¯æŒçµæ´»çš„å‚æ•°è°ƒæ•´ï¼š

yaml
model:
  d_model: 128
  n_layers: 2
  n_heads: 4
  d_ff: 512
training:
  batch_size: 32
  learning_rate: 3e-4
  num_epochs: 50